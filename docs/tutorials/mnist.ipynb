{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an image classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put *FluxTraining.jl* to train a model on the MNIST dataset.\n",
    "\n",
    "MNIST is simple enough that we can focus on the part where *FluxTraining.jl* comes in, the training. If you want to see examples of using FluxTraining.jl on larger datasets, see the documentation of [FastAI.jl](https://github.com/FluxML/FastAI.jl)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*If you want to run this tutorial yourself, you can find the notebook file [here](https://github.com/lorenzoh/FluxTraining.jl/blob/master/docs/tutorials/mnist.ipynb)*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make data loading and batching a bit easier, we'll install an additional dependency:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```julia\n",
    "using Pkg; Pkg.add([\"MLUtils\"])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can import everything we'll need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLUtils: splitobs, unsqueeze\n",
    "using MLDatasets: MNIST\n",
    "using Flux\n",
    "using Flux: onehotbatch\n",
    "using Flux.Data: DataLoader\n",
    "using FluxTraining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 4 pieces that you always need to construct and train a [`Learner`](#):\n",
    "\n",
    "- a model\n",
    "- data\n",
    "- an optimizer; and\n",
    "- a loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a `Learner`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the **data** first.\n",
    "\n",
    "*FluxTraining.jl* is agnostic of the data source. The only requirements are:\n",
    "\n",
    "- it is iterable and each iteration returns a tuple `(xs, ys)`\n",
    "- the model can take in `xs`, i.e. `model(xs)` works; and\n",
    "- the loss function can take model outputs and `ys`, i.e. `lossfn(model(xs), ys)` returns a scalar\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Glossing over the details as it's not the focus of this tutorial, here's the code for getting a data iterator of the MNIST dataset. We use `DataLoaders.DataLoader` to create an iterator of batches from our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = MNIST(:train)[:]\n",
    "\n",
    "const LABELS = 0:9\n",
    "\n",
    "# unsqueeze to reshape from (28, 28, numobs) to (28, 28, 1, numobs)\n",
    "function preprocess((data, targets))\n",
    "    return unsqueeze(data, 3), onehotbatch(targets, LABELS)\n",
    "end\n",
    "\n",
    "\n",
    "# traindata and testdata contain both inputs (pixel values) and targets (correct labels)\n",
    "traindata = MNIST(Float32, :train)[:] |> preprocess\n",
    "testdata = MNIST(Float32, :test)[:] |> preprocess\n",
    "\n",
    "# create iterators\n",
    "trainiter, testiter = DataLoader(traindata, batchsize=128), DataLoader(testdata, batchsize=256);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's create a simple *Flux.jl* **model** that we'll train to classify the MNIST digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Conv((3, 3), 1 => 16, relu, pad=1, stride=2),  \u001b[90m# 160 parameters\u001b[39m\n",
       "  Conv((3, 3), 16 => 32, relu, pad=1),  \u001b[90m# 4_640 parameters\u001b[39m\n",
       "  GlobalMeanPool(),\n",
       "  Flux.flatten,\n",
       "  Dense(32 => 10),                      \u001b[90m# 330 parameters\u001b[39m\n",
       ") \u001b[90m                  # Total: 6 arrays, \u001b[39m5_130 parameters, 20.867 KiB."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Chain(\n",
    "    Conv((3, 3), 1 => 16, relu, pad = 1, stride = 2),\n",
    "    Conv((3, 3), 16 => 32, relu, pad = 1),\n",
    "    GlobalMeanPool(),\n",
    "    Flux.flatten,\n",
    "    Dense(32, 10),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use *categorical cross entropy* as a **loss function** and *ADAM* as an **optimizer**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "lossfn = Flux.Losses.logitcrossentropy\n",
    "optimizer = Flux.ADAM();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to create a [`Learner`](#). At this point you can also add any callbacks, like [`ToGPU`](#) to run the training on your GPU if you have one available. Some callbacks are also [included by default](../callbacks/reference.md).\n",
    "\n",
    "Since we're classifying digits, we also use the [`Metrics`](#) callback to track the accuracy of the model's predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Learner()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner = Learner(model, lossfn; callbacks=[ToGPU(), Metrics(accuracy)], optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With a `Learner` in place, training is as simple as calling [`fit!`](#)`(learner, nepochs, dataiters)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   1.0 │ 1.92511 │  0.30643 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 1 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   1.0 │ 1.56384 │    0.429 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 2 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   2.0 │ 1.40887 │  0.53872 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 2 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   2.0 │ 1.25592 │  0.57578 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 3 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   3.0 │ 1.17799 │  0.64023 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 3 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m   Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼────────┼──────────┤\n",
      "│ ValidationPhase │   3.0 │ 1.0728 │  0.63809 │\n",
      "└─────────────────┴───────┴────────┴──────────┘\n",
      "Epoch 4 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   4.0 │ 1.02755 │  0.69311 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 4 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   4.0 │ 0.95165 │  0.67871 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 5 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   5.0 │ 0.91992 │  0.72615 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 5 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   5.0 │ 0.86318 │  0.70791 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 6 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   6.0 │ 0.83481 │  0.75419 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 6 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   6.0 │ 0.79026 │  0.73604 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 7 TrainingPhase() ...\n",
      "┌───────────────┬───────┬────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m   Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼────────┼──────────┤\n",
      "│ TrainingPhase │   7.0 │ 0.7636 │  0.77762 │\n",
      "└───────────────┴───────┴────────┴──────────┘\n",
      "Epoch 7 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   7.0 │ 0.72974 │  0.75869 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 8 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   8.0 │ 0.70309 │  0.79626 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 8 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m   Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼────────┼──────────┤\n",
      "│ ValidationPhase │   8.0 │ 0.6784 │  0.77363 │\n",
      "└─────────────────┴───────┴────────┴──────────┘\n",
      "Epoch 9 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │   9.0 │ 0.65131 │  0.81166 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 9 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │   9.0 │ 0.63317 │  0.79014 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 10 TrainingPhase() ...\n",
      "┌───────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m         Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├───────────────┼───────┼─────────┼──────────┤\n",
      "│ TrainingPhase │  10.0 │ 0.60669 │  0.82449 │\n",
      "└───────────────┴───────┴─────────┴──────────┘\n",
      "Epoch 10 ValidationPhase() ...\n",
      "┌─────────────────┬───────┬─────────┬──────────┐\n",
      "│\u001b[1m           Phase \u001b[0m│\u001b[1m Epoch \u001b[0m│\u001b[1m    Loss \u001b[0m│\u001b[1m Accuracy \u001b[0m│\n",
      "├─────────────────┼───────┼─────────┼──────────┤\n",
      "│ ValidationPhase │  10.0 │ 0.59359 │  0.80527 │\n",
      "└─────────────────┴───────┴─────────┴──────────┘\n"
     ]
    }
   ],
   "source": [
    "FluxTraining.fit!(learner, 10, (trainiter, testiter))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
