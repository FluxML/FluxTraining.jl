<HTML><head><title>Training an image classifier</title><script src=../../template/highlight.min.js ></script><script src=../../template/julia.min.js ></script><script src=../../template/loadhighlightjs.js ></script><link href=../../template/ansi.css rel=stylesheet ></link><link href=../../template/hugobook.css rel=stylesheet ></link><meta content=Type=text/html; charset=utf-8 http-equiv=Content-Type ></meta><meta name=viewport content=width=device-width, initial-scale=1 ></meta></head><body><input onclick=toggleMenu() id=menu-control class=hidden toggle type=checkbox ></input><input id=toc-control type=checkbox class=hidden toggle ></input><main class=container flex ><aside id=menu-container class=book-menu ><nav class=book-menu-content ><h2 id=title >FluxTraining.jl</h2><div id=sidebar ><div class=doctree ><body><ul><li><p><a href=../../README.md.html title= >README</a></p></li><li><p><a href=../getting_started.md.html title= >Getting started</a></p></li><li><p><a href=../features.md.html title= >Features</a></p></li><li><p>Tutorials</p><ul><li><p><a href=mnist.ipynb.html title= >Training an image classifier</a></p></li><li><p><a href=hyperparameters.md.html title= >Hyperparameter scheduling</a></p></li><li><p><a href=../callbacks/custom.md.html title= >Custom callbacks</a></p></li><li><p><a href=training.md.html title= >Custom training loops</a></p></li></ul></li><li><p>How to</p><ul><li><p><a href=../callbacks/usage.md.html title= >Use callbacks</a></p></li><li><p><a href=../callbacks/tipstricks.md.html title= >Tips &amp; tricks</a></p></li></ul></li><li><p>Reference</p><ul><li><p><a href=../../REFERENCE.html title= >Docstrings</a></p></li><li><p><a href=../callbacks/reference.md.html title= >Callbacks</a></p></li><li><p><a href=../../CHANGELOG.md.html title= >Changelog</a></p></li></ul></li></ul></body></div></div></nav></aside><div class=book-page ><header class=book-header ></header><article><h1 id=training-an-image-classifier >Training an image classifier</h1><p>Let’s put <em>FluxTraining.jl</em> to train a model on the MNIST dataset.</p><p>MNIST is simple enough that we can focus on the part where <em>FluxTraining.jl</em> comes in, the training. If you want to see examples of using FluxTraining.jl on larger datasets, see the documentation of <a href=https://github.com/FluxML/FastAI.jl title= >FastAI.jl</a>.</p><h2 id=setup >Setup</h2><p><em>If you want to run this tutorial yourself, you can find the notebook file <a href=https://github.com/lorenzoh/FluxTraining.jl/blob/master/docs/tutorials/mnist.ipynb title= >here</a></em>.</p><p>To make data loading and batching a bit easier, we’ll install some additional dependencies:</p><pre lang=julia ><code>
using Pkg; Pkg.add([&quot;MLDataPattern&quot;, &quot;DataLoaders&quot;])

</code></pre><p>Now we can import everything we’ll need.</p><pre lang=julia ><code>using DataLoaders: DataLoader
using MLDataPattern: splitobs
using Flux
using FluxTraining</code></pre><h2 id=overview >Overview</h2><p>There are 4 pieces that you always need to construct and train a <a href=../../REFERENCE/FluxTraining.Learner.html ><code>Learner</code></a>:</p><ul><li><p>a model</p></li><li><p>data</p></li><li><p>an optimizer; and</p></li><li><p>a loss function</p></li></ul><h2 id=building-a-learner >Building a <code>Learner</code></h2><p>Let’s look at the <strong>data</strong> first.</p><p><em>FluxTraining.jl</em> is agnostic of the data source. The only requirements are:</p><ul><li><p>it is iterable and each iteration returns a tuple <code>(xs, ys)</code></p></li><li><p>the model can take in <code>xs</code>, i.e. <code>model(xs)</code> works; and</p></li><li><p>the loss function can take model outputs and <code>ys</code>, i.e. <code>lossfn(model(xs), ys)</code> returns a scalar</p></li></ul><p>Glossing over the details as it’s not the focus of this tutorial, here’s the code for getting a data iterator of the MNIST dataset. We use <code>DataLoaders.DataLoader</code> to create an iterator of batches from our dataset.</p><pre lang=julia ><code>xs, ys = (
    # convert each image into h*w*1 array of floats 
    [Float32.(reshape(img, 28, 28, 1)) for img in Flux.Data.MNIST.images()],
    # one-hot encode the labels
    [Float32.(Flux.onehot(y, 0:9)) for y in Flux.Data.MNIST.labels()],
)

# split into training and validation sets
traindata, valdata = splitobs((xs, ys))

# create iterators
trainiter, valiter = DataLoader(traindata, 128, buffered=false), DataLoader(valdata, 256, buffered=false);</code></pre><p>Next, let’s create a simple <em>Flux.jl</em> <strong>model</strong> that we’ll train to classify the MNIST digits.</p><pre lang=julia ><code>model = Chain(
    Conv((3, 3), 1 =&gt; 16, relu, pad = 1, stride = 2),
    Conv((3, 3), 16 =&gt; 32, relu, pad = 1),
    GlobalMeanPool(),
    Flux.flatten,
    Dense(32, 10),
)</code></pre><pre class=coderesult ><code>Chain(Conv((3, 3), 1=>16, relu), Conv((3, 3), 16=>32, relu), GlobalMeanPool(), flatten, Dense(32, 10))</code></pre><p>We’ll use <em>categorical cross entropy</em> as a <strong>loss function</strong> and <em>ADAM</em> as an <strong>optimizer</strong>.</p><pre lang=julia ><code>lossfn = Flux.Losses.logitcrossentropy
optim = Flux.ADAM();</code></pre><p>Now we’re ready to create a <a href=../../REFERENCE/FluxTraining.Learner.html ><code>Learner</code></a>. At this point you can also add any callbacks, like <a href=../../REFERENCE/FluxTraining.ToGPU.html ><code>ToGPU</code></a> to run the training on your GPU if you have one available. Some callbacks are also <a href=../callbacks/reference.md.html title= >included by default</a>.</p><p>Since we’re classifying digits, we also use the <a href=../../REFERENCE/FluxTraining.Metrics.html ><code>Metrics</code></a> callback to track the accuracy of the model’s predictions:</p><pre lang=julia ><code>learner = Learner(model, (trainiter, valiter), optim, lossfn, Metrics(accuracy))</code></pre><pre class=coderesult ><code>Learner()</code></pre><h2 id=training >Training</h2><p>With a <code>Learner</code> inplace, training is as simple as calling <a href=../../REFERENCE/FluxTraining.fit!.html ><code>fit!</code></a><code>(learner, nepochs)</code>.</p><pre lang=julia ><code>FluxTraining.fit!(learner, 10)</code></pre><pre class=codeoutput ><code><span class="sgr32">Epoch 1 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:46</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   1.0 │ 2.04939 │  0.25204 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 1 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   1.0 │ 1.70353 │   0.3821 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 2 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:19</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   2.0 │ 1.58615 │  0.44849 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 2 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   2.0 │ 1.44792 │  0.50544 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 3 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:18</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   3.0 │ 1.36495 │  0.57273 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 3 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   3.0 │ 1.25941 │  0.59525 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 4 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:20</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   4.0 │ 1.18935 │  0.64891 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 4 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">   Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼────────┼──────────┤
│ ValidationPhase │   4.0 │ 1.1076 │  0.66347 │
└─────────────────┴───────┴────────┴──────────┘
<span class="sgr32">Epoch 5 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:19</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   5.0 │ 1.05506 │  0.69386 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 5 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   5.0 │ 0.99203 │  0.70275 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 6 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:18</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   6.0 │ 0.95282 │  0.72533 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 6 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   6.0 │ 0.90209 │  0.73058 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 7 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:19</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   7.0 │ 0.87621 │  0.74563 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 7 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   7.0 │ 0.83402 │  0.74781 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 8 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:18</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   8.0 │ 0.81399 │  0.76282 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 8 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   8.0 │ 0.77623 │  0.76568 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 9 TrainingPhase(): 100%|██████████████████████████| Time: 0:00:18</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │   9.0 │ 0.76236 │  0.77835 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 9 ValidationPhase(): 100%|████████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │   9.0 │ 0.72606 │  0.78079 │
└─────────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 10 TrainingPhase(): 100%|█████████████████████████| Time: 0:00:18</span>
┌───────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">         Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├───────────────┼───────┼─────────┼──────────┤
│ TrainingPhase │  10.0 │ 0.71684 │  0.79175 │
└───────────────┴───────┴─────────┴──────────┘
<span class="sgr32">Epoch 10 ValidationPhase(): 100%|███████████████████████| Time: 0:00:02</span>
┌─────────────────┬───────┬─────────┬──────────┐
│<span class="sgr1">           Phase </span>│<span class="sgr1"> Epoch </span>│<span class="sgr1">    Loss </span>│<span class="sgr1"> Accuracy </span>│
├─────────────────┼───────┼─────────┼──────────┤
│ ValidationPhase │  10.0 │ 0.68353 │  0.79449 │
└─────────────────┴───────┴─────────┴──────────┘
</code></pre><pre class=coderesult ><code>Learner()</code></pre></article><footer class=book-footer ></footer></div><aside class=book-toc ><nav id=toc class=book-toc-content ><ul><li><a href=#training-an-image-classifier >Training an image classifier</a><ul><li><a href=#setup >Setup</a><ul></ul></li><li><a href=#overview >Overview</a><ul></ul></li><li><a href=#building-a-learner >Building a Learner</a><ul></ul></li><li><a href=#training >Training</a><ul></ul></li></ul></li></ul></nav></aside></main></body></HTML>