{"attributes":{"backlinks":[{"tag":"document","title":"Getting started","docid":"FluxTraining@pr-155/doc/docs/getting_started.md"},{"tag":"document","title":"Loss functions","docid":"FluxTraining@pr-155/doc/docs/background/lossfunction.md"},{"tag":"document","title":"Data iterators","docid":"FluxTraining@pr-155/doc/docs/background/dataiterator.md"},{"tag":"document","title":"Optimizers","docid":"FluxTraining@pr-155/doc/docs/background/optimizer.md"}],"path":"/home/runner/.julia/packages/FluxTraining/185if/docs/background/model.md","title":"Models"},"tag":"document","children":[{"attributes":{},"tag":"md","children":[{"attributes":{},"tag":"h1","children":["Models"],"type":"node"},{"attributes":{},"tag":"p","children":["FluxTraining.jl works with all ",{"attributes":{"href":"https://github.com/FluxML/Flux.jl","title":""},"tag":"a","children":["Flux.jl"],"type":"node"},"-compatible models. Unless you are using a ",{"attributes":{"href":"/doc/docs/tutorials/training.md","title":"","document_id":"FluxTraining@pr-155/doc/docs/tutorials/training.md"},"tag":"reference","children":["custom training loop"],"type":"node"},", a ",{"attributes":{},"tag":"code","children":["model"],"type":"node"}," is expected to take a single input ",{"attributes":{},"tag":"code","children":["xs"],"type":"node"},", which corresponds to the encoded inputs returned by your ",{"attributes":{"href":"/doc/docs/background/dataiterator.md","title":"","document_id":"FluxTraining@pr-155/doc/docs/background/dataiterator.md"},"tag":"reference","children":["data iterator"],"type":"node"},". This means the following has to work:"],"type":"node"},{"attributes":{"lang":"julia"},"tag":"codeblock","children":[{"attributes":{},"tag":"julia","children":[{"attributes":{},"tag":"=","children":[{"attributes":{},"tag":"tuple","children":[{"attributes":{},"tag":"Identifier","children":["xs"],"type":"node"},{"attributes":{},"tag":",","children":[","],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"Identifier","children":["ys"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"=","children":["="],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"call","children":[{"attributes":{},"tag":"Identifier","children":["first"],"type":"node"},{"attributes":{},"tag":"(","children":["("],"type":"node"},{"attributes":{},"tag":"Identifier","children":["dataiter"],"type":"node"},{"attributes":{},"tag":")","children":[")"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"NewlineWs","children":["\n"],"type":"node"},{"attributes":{},"tag":"=","children":[{"attributes":{},"tag":"Identifier","children":["Å·s"],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"=","children":["="],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"call","children":[{"attributes":{},"tag":"Identifier","children":["model"],"type":"node"},{"attributes":{},"tag":"(","children":["("],"type":"node"},{"attributes":{},"tag":"Identifier","children":["xs"],"type":"node"},{"attributes":{},"tag":")","children":[")"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"p","children":[{"attributes":{},"tag":"code","children":["model"],"type":"node"}," also has to be differentiable. If you're composing Flux.jl layers, this is likely the case. You can always make sure by testing:"],"type":"node"},{"attributes":{"lang":"julia"},"tag":"codeblock","children":[{"attributes":{},"tag":"julia","children":[{"attributes":{},"tag":"using","children":[{"attributes":{},"tag":"using","children":["using"],"type":"node"},{"attributes":{},"tag":".","children":[{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"Identifier","children":["Flux"],"type":"node"}],"type":"node"},{"attributes":{},"tag":",","children":[","],"type":"node"},{"attributes":{},"tag":".","children":[{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"Identifier","children":["Zygote"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"NewlineWs","children":["\n"],"type":"node"},{"attributes":{},"tag":"NewlineWs","children":["\n"],"type":"node"},{"attributes":{},"tag":"=","children":[{"attributes":{},"tag":"tuple","children":[{"attributes":{},"tag":"Identifier","children":["xs"],"type":"node"},{"attributes":{},"tag":",","children":[","],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"Identifier","children":["ys"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"=","children":["="],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"call","children":[{"attributes":{},"tag":"Identifier","children":["first"],"type":"node"},{"attributes":{},"tag":"(","children":["("],"type":"node"},{"attributes":{},"tag":"Identifier","children":["dataiter"],"type":"node"},{"attributes":{},"tag":")","children":[")"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"NewlineWs","children":["\n"],"type":"node"},{"attributes":{},"tag":"=","children":[{"attributes":{},"tag":"Identifier","children":["lossfn"],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"=","children":["="],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":".","children":[{"attributes":{},"tag":"Identifier","children":["Flux"],"type":"node"},{"attributes":{},"tag":".","children":["."],"type":"node"},{"attributes":{},"tag":"quote","children":[{"attributes":{},"tag":"Identifier","children":["mse"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"NewlineWs","children":["\n"],"type":"node"},{"attributes":{},"tag":"=","children":[{"attributes":{},"tag":"Identifier","children":["grads"],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"=","children":["="],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"do","children":[{"attributes":{},"tag":"call","children":[{"attributes":{},"tag":".","children":[{"attributes":{},"tag":"Identifier","children":["Zygote"],"type":"node"},{"attributes":{},"tag":".","children":["."],"type":"node"},{"attributes":{},"tag":"quote","children":[{"attributes":{},"tag":"Identifier","children":["gradient"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"(","children":["("],"type":"node"},{"attributes":{},"tag":"call","children":[{"attributes":{},"tag":".","children":[{"attributes":{},"tag":"Identifier","children":["Flux"],"type":"node"},{"attributes":{},"tag":".","children":["."],"type":"node"},{"attributes":{},"tag":"quote","children":[{"attributes":{},"tag":"Identifier","children":["params"],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"(","children":["("],"type":"node"},{"attributes":{},"tag":"Identifier","children":["model"],"type":"node"},{"attributes":{},"tag":")","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":")","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"do","children":["do"],"type":"node"},{"attributes":{},"tag":"tuple","children":[{"attributes":{},"tag":"NewlineWs","children":["\n    "],"type":"node"}],"type":"node"},{"attributes":{},"tag":"block","children":[{"attributes":{},"tag":"call","children":[{"attributes":{},"tag":"Identifier","children":["lossfn"],"type":"node"},{"attributes":{},"tag":"(","children":["("],"type":"node"},{"attributes":{},"tag":"call","children":[{"attributes":{},"tag":"Identifier","children":["model"],"type":"node"},{"attributes":{},"tag":"(","children":["("],"type":"node"},{"attributes":{},"tag":"Identifier","children":["xs"],"type":"node"},{"attributes":{},"tag":")","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":",","children":[","],"type":"node"},{"attributes":{},"tag":"Whitespace","children":[" "],"type":"node"},{"attributes":{},"tag":"Identifier","children":["ys"],"type":"node"},{"attributes":{},"tag":")","children":[")"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"NewlineWs","children":["\n"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"end","children":["end"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"},{"attributes":{},"tag":"h2","children":["Creating models"],"type":"node"},{"attributes":{},"tag":"p","children":["The simplest way to create a Flux.jl-compatible model is to use layers from Flux.jl. A good entrypoint is ",{"attributes":{"href":"https://fluxml.ai/Flux.jl/stable/models/basics/","title":""},"tag":"a","children":["this tutorial"],"type":"node"},"in Flux's documentation."],"type":"node"},{"attributes":{},"tag":"p","children":["There is also a large number of packages that provide complete model architectures or domain-specific layers. Below is a non-exhaustive list:"],"type":"node"},{"attributes":{},"tag":"ul","children":[{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://github.com/FluxML/Metalhead.jl","title":""},"tag":"a","children":["Metalhead.jl"],"type":"node"}," implements common model architectures for computer vision,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://github.com/CarloLucibello/GraphNeuralNetworks.jl","title":""},"tag":"a","children":["GraphNeuralNetworks.jl"],"type":"node"}," provides layers and utilities for graph neural networks,"],"type":"node"}],"type":"node"},{"attributes":{},"tag":"li","children":[{"attributes":{},"tag":"p","children":[{"attributes":{"href":"https://github.com/chengchingwen/Transformers.jl","title":""},"tag":"a","children":["Transformers.jl"],"type":"node"}," implements transformer models including pretrained language models"],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}],"type":"node"}