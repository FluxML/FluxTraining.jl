<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en">
<head>
    <meta charset="utf-8" />
    <meta name="generator" content="Publish.jl" />
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="keywords" content="" />
    <title>FluxTraining.jl</title>
    <link rel="stylesheet" href="..&#x2F;..&#x2F;normalize.css" />
    <link rel="stylesheet" href="..&#x2F;..&#x2F;tabulator_simple.min.css" />
    <link rel="stylesheet" href="..&#x2F;..&#x2F;lorenzo.css" />
    <script src="..&#x2F;..&#x2F;versions.js"></script>
    <script src="..&#x2F;..&#x2F;lunr.js"></script>
    <script src="..&#x2F;..&#x2F;highlight.min.js"></script>
    <script src="..&#x2F;..&#x2F;tabulator.min.js"></script>
    <script src="..&#x2F;..&#x2F;julia.min.js"></script>
    <script src="..&#x2F;..&#x2F;julia-repl.min.js"></script>
    <script src="..&#x2F;..&#x2F;publish.js"></script>
    
<link href="https://fonts.googleapis.com/css2?family=Source+Serif+Pro&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Lora:wght@700&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Lora:wght@500&display=swap" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=Lora:ital@1&family=Source+Sans+Pro:wght@700&display=swap" rel="stylesheet">
    <!-- 
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css" integrity="sha384-AfEj0r4/OFrOo5t7NnNe46zW/tFgW6x/bCJG8FqQCEo3+Aro6EYUG4+cU+KJWu/X" crossorigin="anonymous">
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.js" integrity="sha384-g7c+Jr9ZivxKLnZTDUhnkOnsh30B4H0rpLUpJ4jAIKs4fnJI+sEnkvrMWph2EDg4" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/contrib/auto-render.min.js" integrity="sha384-mll67QQFJfxn0IYznZYonOWZ644AWYC+Pt2cHqMaRhXVrursRwvLnLaebdGIlYNa" crossorigin="anonymous"
        onload="renderMathInElement(document.body);"></script>
        -->

</head>
<body>
    <main id="page">
        <div class="menu">
            <div id="projectname">FluxTraining.jl</div>
            <input id="search-input" placeholder="Search">
            <select id="version-selector"></select>
            <svg id="menu-toggler" title="Contents" onclick="toggleIndexPage();" width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 6C2 5.44772 2.44772 5 3 5H21C21.5523 5 22 5.44772 22 6C22 6.55228 21.5523 7 21 7H3C2.44772 7 2 6.55228 2 6Z" fill="currentColor" /><path d="M2 12.0322C2 11.4799 2.44772 11.0322 3 11.0322H21C21.5523 11.0322 22 11.4799 22 12.0322C22 12.5845 21.5523 13.0322 21 13.0322H3C2.44772 13.0322 2 12.5845 2 12.0322Z" fill="currentColor" /><path d="M3 17.0645C2.44772 17.0645 2 17.5122 2 18.0645C2 18.6167 2.44772 19.0645 3 19.0645H21C21.5523 19.0645 22 18.6167 22 18.0645C22 17.5122 21.5523 17.0645 21 17.0645H3Z" fill="currentColor" /></svg>
        </div>
        <div id="toc"><p><a href="../../README.html">README</a></p>
<h3 id="start-here"><a href="../../#start-here" class="anchor"></a>Start here</h3>
<ul>
<li><a href="../../docs/getting_started.html">Getting started</a></li>
<li><a href="../../docs/overview.html">User guide</a></li>
<li><a href="../../docs/features.html">Features</a></li>
</ul>
<h3 id="library"><a href="../../#library" class="anchor"></a>Library</h3>
<ul>
<li><a href="../../docs/training/basics.html">Training loop</a></li>
<li><a href="../../docs/callbacks/usage.html">Using callbacks</a></li>
<li><a href="../../docs/callbacks/reference.html">Callback reference</a></li>
<li><a href="../../docs/callbacks/custom.html">Custom callbacks</a></li>
<li><a href="../../docs/callbacks/tipstricks.html">Tips &amp; tricks</a></li>
</ul>
<h3 id="referencedocstringsmd"><a href="../../#referencedocstringsmd" class="anchor"></a><a href="../../docstrings.html">Reference</a></h3>
<h3 id="tutorials"><a href="../../#tutorials" class="anchor"></a>Tutorials</h3>
<ul>
<li><a href="../../docs/tutorials/mnist.html">MNIST training</a></li>
<li><a href="../../docs/tutorials/hyperparameters.html">Hyperparameter scheduling</a></li>
</ul>
<h3 id="other"><a href="../../#other" class="anchor"></a>Other</h3>
<ul>
<li><a href="../../docs/status.html">Project status</a></li>
<li><a href="../../docs/ecosystem.html">Ecosystem</a></li>
</ul>
</div>
        <article><pre><code class="language-julia">using Pkg  # src
Pkg.activate(&quot;../FluxTraining/docs&quot;)  # src
</code></pre>
<p>Let’s put <em>FluxTraining.jl</em> to train a model on the MNIST dataset.</p>
<p>MNIST is simple enough that we can focus on the part where <em>FluxTraining.jl</em> comes in, the training.</p>
<h2 id="setup"><a href="#setup" class="anchor"></a>Setup</h2>
<p><em>if you want to run this tutorial yourself, you can find the notebook file <a href="https://github.com/lorenzoh/FluxTraining.jl/blob/master/docs/tutorials/mnist.ipynb">here</a></em>.
To make data loading and batching a bit easier, we’ll install some additional dependencies:</p>
<pre><code class="language-julia">using Pkg
Pkg.add(url=&quot;https://github.com/lorenzoh/DataLoaders.jl&quot;)
Pkg.add(&quot;MLDataPattern&quot;)
</code></pre>
<p>Now we can import everything we’ll need.</p>
<pre><code class="language-julia">using DataLoaders: DataLoader
using MLDataPattern: splitobs
using Flux
using FluxTraining
</code></pre>
<h2 id="overview"><a href="#overview" class="anchor"></a>Overview</h2>
<p>There are 4 pieces that you always need to construct and train a <a href="../../docstrings/FluxTraining.Learner.html"><code>Learner</code></a>:</p>
<ul>
<li>a model</li>
<li>data</li>
<li>an optimizer; and</li>
<li>a loss function</li>
</ul>
<h2 id="building-a-learner"><a href="#building-a-learner" class="anchor"></a>Building a <code>Learner</code></h2>
<p>Let’s look at the <strong>data</strong> first.</p>
<p><em>FluxTraining.jl</em> is agnostic of the data source. The only requirements are:</p>
<ul>
<li>it is iterable and each iteration returns a tuple <code>(xs, ys)</code></li>
<li>the model can take in <code>xs</code>, i.e. <code>model(xs)</code> works; and</li>
<li>the loss function can take model outputs and <code>ys</code>, i.e. <code>lossfn(model(xs), ys)</code> returns a scalar</li>
</ul>
<p>Glossing over the details as it’s not the focus of this tutorial, here’s the code for getting a data iterator of the MNIST dataset. We use <code>DataLoaders.DataLoader</code> to create an iterator of batches from our dataset.</p>
<pre><code class="language-julia">xs, ys = (
    # convert each image into h*w*1 array of floats 
    [Float32.(reshape(img, 28, 28, 1)) for img in Flux.Data.MNIST.images()],
    # one-hot encode the labels
    [Flux.onehot(y, 0:9) for y in Flux.Data.MNIST.labels()],
)

# split into training and validation sets
traindata, valdata = splitobs((xs, ys))

# create iterators
trainiter, valiter = DataLoader(traindata, 128), DataLoader(valdata, 256);
</code></pre>
<p>Next, let’s create a simple <em>Flux.jl</em> <strong>model</strong> that we’ll train to classify the MNIST digits.</p>
<pre><code class="language-julia">model = Chain(
    Conv((3, 3), 1 =&gt; 16, relu, pad = 1, stride = 2),
    Conv((3, 3), 16 =&gt; 32, relu, pad = 1),
    GlobalMeanPool(),
    Flux.flatten,
    Dense(32, 10),
)
</code></pre>
<p>We’ll use <em>categorical cross entropy</em> as a <strong>loss function</strong> and <em>ADAM</em> as an <strong>optimizer</strong>.</p>
<pre><code class="language-julia">lossfn = Flux.Losses.logitcrossentropy
optim = Flux.ADAM();
</code></pre>
<p>Now we’re ready to create a <a href="../../docstrings/FluxTraining.Learner.html"><code>Learner</code></a>. At this point you can also add any callbacks, like <a href="../../docstrings/FluxTraining.ToGPU.html"><code>ToGPU</code></a> to run the training on your GPU if you have one available. Some callbacks are also <a href="../callbacks/reference.html">included by default</a>.</p>
<p>Since we’re classifying digits, we also use the <a href="../../docstrings/FluxTraining.Metrics.html"><code>Metrics</code></a> callback to track the accuracy of the model’s predictions:</p>
<pre><code class="language-julia">learner = Learner(model, (trainiter, valiter), optim, lossfn, ToGPU(), Metrics(accuracy))
</code></pre>
<h2 id="training"><a href="#training" class="anchor"></a>Training</h2>
<p>With a <code>Learner</code> inplace, training is as simple as calling <a href="../../docstrings/FluxTraining.fit!.html"><code>fit!</code></a><code>(learner, nepochs)</code>.</p>
<pre><code class="language-julia">FluxTraining.fit!(learner, 10)
</code></pre>
</article>
        <div id="page-navigation">
            <a id="previous-page" title="Previous" href="..&#x2F;..&#x2F;docstrings.html"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M16.2426 6.34317L14.8284 4.92896L7.75739 12L14.8285 19.0711L16.2427 17.6569L10.5858 12L16.2426 6.34317Z" fill="currentColor" /></svg></a>
            <a id="next-page" title="Next" href="hyperparameters.html"><svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M10.5858 6.34317L12 4.92896L19.0711 12L12 19.0711L10.5858 17.6569L16.2427 12L10.5858 6.34317Z" fill="currentColor" /></svg></a>
        </div>
        <footer>
            Built with <a target="_blank" href="https://github.com/MichaelHatherly/Publish.jl">Publish.jl</a> and the <a target="_blank" href="https://julialang.org">Julia Language</a>.
        </footer>
    </main>
    <script>hljs.initHighlightingOnLoad();</script>
</body>
</html>
